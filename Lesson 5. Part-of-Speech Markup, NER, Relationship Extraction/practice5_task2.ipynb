{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice5_tasc2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK2o1sQ8SJo5"
      },
      "source": [
        "# !pip install corus\n",
        "# !pip install razdel\n",
        "# !wget http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn8H8TKEEarK"
      },
      "source": [
        "import corus\n",
        "\n",
        "from razdel import tokenize"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8h-xq6KSRyo",
        "outputId": "332a172c-52e6-428c-8250-e177dd49c0b1"
      },
      "source": [
        "path = 'Persons-1000.zip'\n",
        "records = corus.persons.load_persons(path)\n",
        "rec = next(records)\n",
        "rec"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PersonsMarkup(\n",
              "    text='Россия рассчитывает на конструктивное воздействие США на Грузию\\r\\n\\r\\n04/08/2008 12:08\\r\\n\\r\\nМОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел России Григорий Карасин заявил в телефонном разговоре с заместителем госсекретаря США Дэниэлом Фридом.\\r\\n\\r\\n\"С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг Южной Осетии, противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений\", - говорится в сообщении.\\r\\n\\r\\n\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает также на конструктивное воздействие со стороны Вашингтона\", - сообщил МИД России. ',\n",
              "    spans=[PersonsSpan(\n",
              "         id=1,\n",
              "         start=308,\n",
              "         stop=324,\n",
              "         value='ГРИГОРИЙ КАРАСИН'\n",
              "     ), PersonsSpan(\n",
              "         id=2,\n",
              "         start=387,\n",
              "         stop=402,\n",
              "         value='ДЭНИЭЛ ФРИД'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMccQUNbQAUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7710cd54-4a09-48b9-cf80-20f901e3c471"
      },
      "source": [
        "word_tag = []\n",
        "\n",
        "for rec in records:\n",
        "  for r in rec.spans:\n",
        "    for t in tokenize(rec.text):\n",
        "      if (t.start >= r.start) and (t.stop <= r.stop):\n",
        "        word_tag.append((rec.text[t.start:t.stop], 'PERSON'))\n",
        "      else:\n",
        "        word_tag.append((rec.text[t.start:t.stop], 'NO_PERSON'))\n",
        "\n",
        "print(len(word_tag)) \n",
        "print(word_tag[:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3715842\n",
            "[('Комиссар', 'NO_PERSON'), ('СЕ', 'NO_PERSON'), ('критикует', 'NO_PERSON'), ('ограничительную', 'NO_PERSON'), ('политику', 'NO_PERSON')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geHicQxqtQ9O",
        "outputId": "e7cb0393-fb4e-465b-9026-284a9ce56bf7"
      },
      "source": [
        "for i in word_tag[:1000]:\n",
        "  if i[1] == 'PERSON':\n",
        "    print(i)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Томас', 'PERSON')\n",
            "('Хаммарберг', 'PERSON')\n",
            "('(', 'PERSON')\n",
            "('Thomas', 'PERSON')\n",
            "('Hammarberg', 'PERSON')\n",
            "(')', 'PERSON')\n",
            "('Хаммарберг', 'PERSON')\n",
            "('Михаила', 'PERSON')\n",
            "('Саакашвили', 'PERSON')\n",
            "('Егора', 'PERSON')\n",
            "('Борисова', 'PERSON')\n",
            "('Егора', 'PERSON')\n",
            "('Борисова', 'PERSON')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYVPZQrgT_0o"
      },
      "source": [
        "# Проверить насколько хорошо работает NER\n",
        "\n",
        "## 1. взять нер из nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXNW0aIG1Hgf",
        "outputId": "d600245f-c855-40de-f8ae-a6f1373d305a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('names')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voP8B_sz3Jeg",
        "outputId": "7fe4d315-5693-4689-a212-59d4575fcaa7"
      },
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label()) for chunk in nltk.ne_chunk(word_tag[:200_000]) if hasattr(chunk, 'label')}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('AP', 'ORGANIZATION'),\n",
              " ('Clinton', 'PERSON'),\n",
              " ('HSBC', 'ORGANIZATION'),\n",
              " ('John', 'PERSON'),\n",
              " ('John Huntsman Jr', 'PERSON'),\n",
              " ('John Roos', 'PERSON'),\n",
              " ('New York', 'GPE'),\n",
              " ('Washington', 'GPE'),\n",
              " ('Washington Post', 'ORGANIZATION'),\n",
              " ('САО', 'ORGANIZATION')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSt3mL37B4_X"
      },
      "source": [
        "#### Вывод:\n",
        " - ne_chunk не распознает имена на кирилице\n",
        " - однако он распознает организации на кирилице\n",
        "\n",
        "## 2. проверить deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0SFLjqrCaDl"
      },
      "source": [
        "# !python -m venv env\n",
        "# !pip install deeppavlov\n",
        "# !python -m deeppavlov install squad_bert\n",
        "# !python -m deeppavlov install ner_ontonotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOlvtCuGXWBU"
      },
      "source": [
        "import deeppavlov\n",
        "from deeppavlov import configs, build_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVuZfTFqDMKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3ea0d4-0109-4e9c-aab9-3de063523506"
      },
      "source": [
        "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 16:19:31.411 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle to /root/.deeppavlov/models/entity_and_type_detection_rus.pickle\n",
            "100%|██████████| 2.07M/2.07M [00:00<00:00, 5.60MB/s]\n",
            "2021-04-10 16:19:32.412 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz to /root/.deeppavlov/models/ner_cq_rus.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [02:05<00:00, 10.5MB/s]\n",
            "2021-04-10 16:21:38.381 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /root/.deeppavlov/models/ner_cq_rus.tar.gz archive into /root/.deeppavlov/models/ner_ent_and_type_rus\n",
            "2021-04-10 16:21:56.369 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 663M/663M [00:55<00:00, 11.9MB/s]\n",
            "2021-04-10 16:22:52.292 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 16:23:03.936 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:571: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 16:23:35.594 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ent_and_type_rus/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ent_and_type_rus/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "712ywsVXlQoN"
      },
      "source": [
        "deeppavlov_ner(word_tag[:10000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6jcAuSCGnp"
      },
      "source": [
        "#### Вывод:\n",
        "- на деппавлове падает колаб\n",
        "\n",
        "## 3. написать свой нер попробовать разные подходы (с доп информацией без) так же с учётом соседей и без них"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8RjqFnndKF"
      },
      "source": [
        "from nltk.tag import SequentialBackoffTagger\n",
        "from nltk.corpus import names\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RabKjoBtCvE",
        "outputId": "153ea336-0162-474d-90ad-6ddc33ed72c2"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for tok, lbl in word_tag:\n",
        "  X.append(tok)\n",
        "  y.append(lbl)\n",
        "\n",
        "X[:5], y[:5]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Комиссар', 'СЕ', 'критикует', 'ограничительную', 'политику'],\n",
              " ['NO_PERSON', 'NO_PERSON', 'NO_PERSON', 'NO_PERSON', 'NO_PERSON'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOGLcyy2utXP",
        "outputId": "1628eaa0-a7a3-4641-8aa7-83f894e0ce51"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y_train_test = le.fit_transform(y)\n",
        "print(le.classes_)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NO_PERSON' 'PERSON']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSGFReomnPFm"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train_test, test_size=0.3)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9XgFCjXvYPf"
      },
      "source": [
        "hvec_ch = HashingVectorizer(ngram_range=(1,5), analyzer='char_wb', n_features=100)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Aa2iUSwQve"
      },
      "source": [
        "X_train_vec = hvec_ch.fit_transform(X_train)\n",
        "X_test_vec = hvec_ch.transform(X_test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46T0n7f5x77i",
        "outputId": "06b7cd1c-d3f1-4ed3-9989-ccb67a7a447a"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQuz4bF_ykya",
        "outputId": "e7e3724a-adbd-4814-e264-72076cfb6c7f"
      },
      "source": [
        "roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDNPC-vWCMvj"
      },
      "source": [
        "#### Выводы:\n",
        "- roc_auc_score показал, что шанс верного угадывания персоны случаен\n",
        "\n",
        "#### 4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется\n",
        "\n",
        "- NER из nltk хорошо угадывает персон, чьи имена написаны латиницей\n",
        "- Кастомный NER показал плохой результат"
      ]
    }
  ]
}